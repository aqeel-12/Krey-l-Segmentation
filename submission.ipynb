{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from reformat import *\n",
    "from architecture.WordSegPreProcessing import *\n",
    "\n",
    "fn = \"train.tsv\"\n",
    "x, y = file_to_table(read_file(fn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
    "preprocessor = WordSegPreProcessing(X_train, y_train, segment_to_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = preprocessor.x, preprocessor.y\n",
    "X_test, y_test = preprocessor.extract_pairs(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised NGramTagger with Backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architecture.NgramSupervisedTagger import NGramSupervisedTagger\n",
    "ng = NGramSupervisedTagger(X_train, y_train, ngram_choice=2)\n",
    "ng.create_n_gram_tagger()\n",
    "ng.f1_by_tags(X_test, y_test)[\"I\"] #F1 score for just I tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architecture.HMMSupervisedTagger import HMMSupervisedTagger\n",
    "hmm = HMMSupervisedTagger(X_train, y_train)\n",
    "hmm.train()\n",
    "hmm.f1_by_tags(X_test, y_test)[\"I\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same thing as HMM Tagger but instead of just using the provided characters, I manually engineered some features (probably not the best bleh)... You can check it out in `architecture.WordSegPreProcessing.apply_features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architecture.HMMSupervisedTagger import HMMSupervisedTagger\n",
    "hmm2 = HMMSupervisedTagger(preprocessor.generate_features(X_train), y_train)\n",
    "hmm2.train()\n",
    "hmm2.f1_by_tags(preprocessor.generate_features(X_test), y_test)[\"I\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm2.tagger.best_path_simple(preprocessor.apply_features(X_test[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architecture.utils import *\n",
    "x, y = file_to_table(read_file(fn))\n",
    "feedX, feedY = preprocessor.extract_pairs(x[:650], y[:650])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX2, testY2 = preprocessor.extract_pairs(x[650:], y[650:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedX = list(map(lambda x: preprocessor.let2index(x), feedX ))\n",
    "feedY = list(map(lambda y: preprocessor.tag2index(y), feedY))\n",
    "testX2 = list(map(lambda x: preprocessor.let2index(x), testX2))\n",
    "testY2 = list(map(lambda x: preprocessor.tag2index(x), testY2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize with some probs by running HMM on the feeder set\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "init_tmat = np.zeros((len(preprocessor.index_tag),\n",
    "                     len(preprocessor.index_tag)))\n",
    "\n",
    "init_emission = np.zeros(\n",
    "    (len(preprocessor.index_tag), len(preprocessor.index_vocab)))\n",
    "trainer = nltk.HiddenMarkovModelTrainer()\n",
    "tagger = trainer.train_supervised(\n",
    "           tuple_xy4nltk(feedX, feedY))\n",
    "for k in tagger._transitions.keys():\n",
    "    for v in tagger._transitions[k].samples():\n",
    "        init_tmat[k][v] = tagger._transitions[k].prob(v)\n",
    "    for let in tagger._outputs[k].samples():\n",
    "        init_emission[k][let] = tagger._outputs[k].prob(let)\n",
    "init_state_distrib = np.array([0.5, 0.5])  # because always start with B\n",
    "\n",
    "#init_tmat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add 0.05 alpha smoothing here cause I can't absorb to itself but heurestically, we know it is not true\n",
    "init_tmat[preprocessor.index_tag[\"I\"]][preprocessor.index_tag[\"I\"]] += 0.05\n",
    "init_tmat[preprocessor.index_tag[\"I\"]][preprocessor.index_tag[\"B\"]] -= 0.05\n",
    "print(init_tmat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architecture.Unsupervised import UnSupervised\n",
    "unsupervised = UnSupervised(init_tmat, init_emission, init_state_distrib)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = []\n",
    "for ind in range(len(testX2)):\n",
    "    tmat, emission, start, end = unsupervised.baum_welch(testX2[ind], 10)\n",
    "    resultant = unsupervised.viterbi(testX2[ind], emission, tmat, {i: v for i, v in enumerate(start)})\n",
    "    resultant[0] = preprocessor.index_tag[\"B\"]\n",
    "    y_predicted.append(resultant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_by_tags(y_predicted, testY2)[preprocessor.index_tag[\"I\"]]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38d37c7b51a76fad05d5106cda319bdfc676f147592bff32468239985737bad5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
