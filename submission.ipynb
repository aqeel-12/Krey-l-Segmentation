{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from reformat import *\n",
    "from architecture.WordSegPreProcessing import *\n",
    "\n",
    "fn = \"train.tsv\"\n",
    "x, y = file_to_table(read_file(fn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
    "preprocessor = WordSegPreProcessing(X_train, y_train, segment_to_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = preprocessor.x, preprocessor.y\n",
    "X_test, y_test = preprocessor.extract_pairs(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised NGramTagger with Backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a8nguyen/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n",
      "/Users/a8nguyen/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/Users/a8nguyen/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/Users/a8nguyen/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "/Users/a8nguyen/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/Users/a8nguyen/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/Users/a8nguyen/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/Users/a8nguyen/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/Users/a8nguyen/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/Users/a8nguyen/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8827667057444314"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from architecture.NgramSupervisedTagger import NGramSupervisedTagger\n",
    "ng = NGramSupervisedTagger(X_train, y_train, ngram_choice=2)\n",
    "ng.create_n_gram_tagger()\n",
    "ng.f1_by_tags(X_test, y_test)[\"I\"] #F1 score for just I tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8792497069167644"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from architecture.HMMSupervisedTagger import HMMSupervisedTagger\n",
    "hmm = HMMSupervisedTagger(X_train, y_train)\n",
    "hmm.train()\n",
    "hmm.f1_by_tags(X_test, y_test)[\"I\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same thing as HMM Tagger but instead of just using the provided characters, I manually engineered some features (probably not the best bleh)... You can check it out in `architecture.WordSegPreProcessing.apply_features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9383177570093459"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from architecture.HMMSupervisedTagger import HMMSupervisedTagger\n",
    "hmm2 = HMMSupervisedTagger(preprocessor.generate_features(X_train), y_train)\n",
    "hmm2.train()\n",
    "hmm2.f1_by_tags(preprocessor.generate_features(X_test), y_test)[\"I\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B', 'B', 'B', 'B', 'I', 'B', 'B']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm2.tagger.best_path_simple(preprocessor.apply_features(X_test[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architecture.utils import *\n",
    "x, y = file_to_table(read_file(fn))\n",
    "feedX, feedY = preprocessor.extract_pairs(x[:650], y[:650])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX2, testY2 = preprocessor.extract_pairs(x[650:], y[650:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedX = list(map(lambda x: preprocessor.let2index(x), feedX ))\n",
    "feedY = list(map(lambda y: preprocessor.tag2index(y), feedY))\n",
    "testX2 = list(map(lambda x: preprocessor.let2index(x), testX2))\n",
    "testY2 = list(map(lambda x: preprocessor.tag2index(x), testY2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize with some probs by running HMM on the feeder set\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "init_tmat = np.zeros((len(preprocessor.index_tag),\n",
    "                     len(preprocessor.index_tag)))\n",
    "\n",
    "init_emission = np.zeros(\n",
    "    (len(preprocessor.index_tag), len(preprocessor.index_vocab)))\n",
    "trainer = nltk.HiddenMarkovModelTrainer()\n",
    "tagger = trainer.train_supervised(\n",
    "           tuple_xy4nltk(feedX, feedY))\n",
    "for k in tagger._transitions.keys():\n",
    "    for v in tagger._transitions[k].samples():\n",
    "        init_tmat[k][v] = tagger._transitions[k].prob(v)\n",
    "    for let in tagger._outputs[k].samples():\n",
    "        init_emission[k][let] = tagger._outputs[k].prob(let)\n",
    "init_state_distrib = np.array([0.5, 0.5])  # always start w B\n",
    "\n",
    "#init_tmat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.89451595 0.10548405]\n",
      " [0.95       0.05      ]]\n"
     ]
    }
   ],
   "source": [
    "#add 0.05 alpha smoothing here cause I can't absorb to itself but heurestically, we know it is not true\n",
    "init_tmat[preprocessor.index_tag[\"I\"]][preprocessor.index_tag[\"I\"]] += 0.05\n",
    "init_tmat[preprocessor.index_tag[\"I\"]][preprocessor.index_tag[\"B\"]] -= 0.05\n",
    "print(init_tmat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architecture.Unsupervised import UnSupervised\n",
    "unsupervised = UnSupervised(init_tmat, init_emission, init_state_distrib)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a8nguyen/Desktop/undergrad/fall22/csci4845/kreyol_segmentation/Krey-l-Segmentation/architecture/Unsupervised.py:105: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  new_tmat[sj][si] = transition_aux[si][sj]/norm_factor\n",
      "/Users/a8nguyen/Desktop/undergrad/fall22/csci4845/kreyol_segmentation/Krey-l-Segmentation/architecture/Unsupervised.py:108: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if np.isnan(emission_aux[si][o]/norm_factor):\n",
      "/Users/a8nguyen/Desktop/undergrad/fall22/csci4845/kreyol_segmentation/Krey-l-Segmentation/architecture/Unsupervised.py:116: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  for si, term in enumerate(prod_alpha_beta_normed)]\n",
      "/Users/a8nguyen/Desktop/undergrad/fall22/csci4845/kreyol_segmentation/Krey-l-Segmentation/architecture/Unsupervised.py:71: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sum(prod_alpha_beta)  # normalized alpha dot beta\n",
      "/Users/a8nguyen/Desktop/undergrad/fall22/csci4845/kreyol_segmentation/Krey-l-Segmentation/architecture/Unsupervised.py:99: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  beta_now/(sum(prod_alpha_beta)[i])\n"
     ]
    }
   ],
   "source": [
    "y_predicted = []\n",
    "for ind in range(len(testX2)):\n",
    "    tmat, emission, start, end = unsupervised.baum_welch(testX2[ind], 10)\n",
    "    resultant = unsupervised.viterbi(testX2[ind], emission, tmat, {i: v for i, v in enumerate(start)})\n",
    "    resultant[0] = preprocessor.index_tag[\"B\"]\n",
    "    y_predicted.append(resultant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7553418803418803"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_by_tags(y_predicted, testY2)[preprocessor.index_tag[\"I\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running on test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "supervision test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = \"test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTest = []\n",
    "for line in read_file(test_file):\n",
    "    xTest.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTest_reformatted, _ = preprocessor.extract_pairs(xTest, xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPred_super = list(map(lambda i: hmm2.tagger.best_path_simple(preprocessor.apply_features(i)), xTest_reformatted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#super_spell = open('super_spell.txt', 'w')\n",
    "#for i in range(len(yPred_super)):\n",
    "#    print(tag_to_segment(\n",
    "#    yPred_super[i], xTest[i]),\n",
    "#    file=super_spell)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "semi supervision test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPred_semi = []\n",
    "for ind in range(len(xTest_reformatted)):\n",
    "    curWord = preprocessor.let2index(xTest_reformatted[ind])\n",
    "    tmat, emission, start, end = unsupervised.baum_welch(curWord, 10)\n",
    "    resultant = unsupervised.viterbi(curWord, emission, tmat, {\n",
    "                                     i: v for i, v in enumerate(start)})\n",
    "    resultant[0] = preprocessor.index_tag[\"B\"]\n",
    "    resultant_to_BI =  list(map(lambda y: preprocessor.index2tag[y], resultant))\n",
    "    yPred_semi.append(resultant_to_BI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B', 'B', 'B', 'B', 'B']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yPred_semi[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#semi_spell = open('semi_spell.txt', 'w')\n",
    "#for i in range(len(yPred_semi)):\n",
    "#    print(tag_to_segment(\n",
    "#        yPred_semi[i], xTest[i]),\n",
    "#        file=semi_spell)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38d37c7b51a76fad05d5106cda319bdfc676f147592bff32468239985737bad5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
