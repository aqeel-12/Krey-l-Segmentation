{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from reformat import *\n",
    "from architecture.WordSegPreProcessing import *\n",
    "\n",
    "fn = \"train.tsv\"\n",
    "x, y = file_to_table(read_file(fn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
    "preprocessor = WordSegPreProcessing(X_train, y_train, segment_to_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = preprocessor.x, preprocessor.y\n",
    "X_test, y_test = preprocessor.extract_pairs(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised NGramTagger with Backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a8nguyen/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n",
      "/Users/a8nguyen/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/Users/a8nguyen/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/Users/a8nguyen/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "/Users/a8nguyen/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/Users/a8nguyen/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/Users/a8nguyen/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/Users/a8nguyen/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/Users/a8nguyen/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/Users/a8nguyen/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8905882352941177"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from architecture.NgramSupervisedTagger import NGramSupervisedTagger\n",
    "ng = NGramSupervisedTagger(X_train, y_train, ngram_choice=2)\n",
    "ng.create_n_gram_tagger()\n",
    "ng.f1_by_tags(X_test, y_test)[\"I\"] #F1 score for just I tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8894117647058822"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from architecture.HMMSupervisedTagger import HMMSupervisedTagger\n",
    "hmm = HMMSupervisedTagger(X_train, y_train)\n",
    "hmm.train()\n",
    "hmm.f1_by_tags(X_test, y_test)[\"I\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same thing as HMM Tagger but instead of just using the provided characters, I manually engineered some features (probably not the best bleh)... You can check it out in `architecture.WordSegPreProcessing.apply_features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9448621553884713"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from architecture.HMMSupervisedTagger import HMMSupervisedTagger\n",
    "hmm2 = HMMSupervisedTagger(preprocessor.generate_features(X_train), y_train)\n",
    "hmm2.train()\n",
    "hmm2.f1_by_tags(preprocessor.generate_features(X_test), y_test)[\"I\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B', 'B', 'B', 'I', 'B', 'B', 'B', 'B', 'I', 'B']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm2.tagger.best_path_simple(preprocessor.apply_features(X_test[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architecture.utils import *\n",
    "x, y = file_to_table(read_file(fn))\n",
    "feedX, feedY = preprocessor.extract_pairs(x[:650], y[:650])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX2, testY2 = preprocessor.extract_pairs(x[650:], y[650:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedX = list(map(lambda x: preprocessor.let2index(x), feedX ))\n",
    "feedY = list(map(lambda y: preprocessor.tag2index(y), feedY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize with some probs\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "init_tmat = np.zeros((len(preprocessor.index_tag),\n",
    "                     len(preprocessor.index_tag)))\n",
    "\n",
    "init_emission = np.zeros(\n",
    "    (len(preprocessor.index_tag), len(preprocessor.index_vocab)))\n",
    "trainer = nltk.HiddenMarkovModelTrainer()\n",
    "tagger = trainer.train_supervised(\n",
    "           tuple_xy4nltk(feedX, feedY))\n",
    "for k in tagger._transitions.keys():\n",
    "    for v in tagger._transitions[k].samples():\n",
    "        init_tmat[k][v] = tagger._transitions[k].prob(v)\n",
    "    for let in tagger._outputs[k].samples():\n",
    "        init_emission[k][let] = tagger._outputs[k].prob(let)\n",
    "init_state_distrib = np.array([0, 1.0])  # because always start with B\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04002929, 0.        , 0.02294362, 0.01342446, 0.03075421,\n",
       "        0.00781059, 0.01269221, 0.03270686, 0.08445204, 0.01635343,\n",
       "        0.01586527, 0.12570173, 0.04027337, 0.04491091, 0.03783256,\n",
       "        0.05296558, 0.02172321, 0.05735904, 0.        , 0.03587991,\n",
       "        0.03685624, 0.07883817, 0.09421528, 0.01440078, 0.        ,\n",
       "        0.01830608, 0.06370515],\n",
       "       [0.        , 0.        , 0.        , 0.00265252, 0.        ,\n",
       "        0.        , 0.        , 0.75596817, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.08488064, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.15649867,\n",
       "        0.        , 0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_emission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class UnSupervised:\n",
    "    def __init__(self, tmat, emission, initial_distrib):\n",
    "\n",
    "        self.tmat = tmat\n",
    "        self.emission = emission\n",
    "        self.initial_prob = initial_distrib\n",
    "\n",
    "        self.num_states = len(self.tmat)\n",
    "        self.num_letters = len(self.emission[0])\n",
    "\n",
    "    def calculate_beta_backward(self, o_seq, tmat, emission, end_prob=[0.5, 0.5]):\n",
    "        backward_table = np.zeros((self.num_states, len(o_seq)))  # vit table\n",
    "\n",
    "        backward_table[:, -1] = end_prob\n",
    "        #print(backward_table)\n",
    "\n",
    "        for i in range(len(o_seq)-2, -1, -1):  # start filling in the table\n",
    "            beta_s_t = 0\n",
    "            for tag_cell in range(self.num_states):\n",
    "                for tag_prev in range(self.num_states):\n",
    "                    beta_s_t += backward_table[tag_prev][i+1] * \\\n",
    "                        tmat[tag_cell][tag_prev] * \\\n",
    "                        emission[tag_prev][o_seq[i+1]]\n",
    "                backward_table[tag_cell][i] = beta_s_t\n",
    "                beta_s_t = 0\n",
    "        return backward_table\n",
    "\n",
    "    def calculate_alpha_forward(self, o_seq, tmat, emission):\n",
    "\n",
    "        forward_table = np.zeros((self.num_states, len(o_seq)))  # vit table\n",
    "        emission_t0 = [self.emission[i][o_seq[0]]\n",
    "                       for i in range(self.num_states)]\n",
    "        forward_table[:, 0] = np.multiply(emission_t0, self.initial_prob)\n",
    "\n",
    "        for i in range(1, len(o_seq)):  # start filling in the table\n",
    "            alpha_s_t = 0\n",
    "            for tag_cell in range(self.num_states):\n",
    "                for tag_prev in range(self.num_states):\n",
    "                    alpha_s_t += forward_table[tag_prev][i-1] * \\\n",
    "                        tmat[tag_prev][tag_cell] * \\\n",
    "                        emission[tag_cell][o_seq[i]]\n",
    "                forward_table[tag_cell][i] = alpha_s_t\n",
    "                alpha_s_t = 0\n",
    "        return forward_table\n",
    "\n",
    "    def baum_welch(self, o_seq, n_iter):\n",
    "        tmat = self.tmat\n",
    "        emission = self.emission\n",
    "        M = len(tmat[0])\n",
    "        T = len(o_seq)\n",
    "\n",
    "        for _ in range(n_iter):\n",
    "            alpha = self.calculate_alpha_forward(\n",
    "                o_seq, tmat, emission)  # matrix\n",
    "            beta = self.calculate_beta_backward(o_seq, tmat, emission)\n",
    "            prod_alpha_beta = alpha*beta\n",
    "            prod_alpha_beta_normed = prod_alpha_beta/sum(prod_alpha_beta) #normalized alpha dot beta\n",
    "\n",
    "            #emission aux is well emission auxillary Sum(P(state_i |observed_t) of all time t ) \n",
    "            #-----seq-------\n",
    "            #|\n",
    "            #state\n",
    "            #|\n",
    "            emission_aux = defaultdict(lambda : defaultdict(float))\n",
    "            #transition aux. \n",
    "            # LESSON LEARNED!! KNOW MATRIX ALGEBRA LIKE A PRO to avoid calculating entry by entry like this!!\n",
    "            #P(state_i|state_j)\n",
    "            transition_aux = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "            for i,obs in enumerate(o_seq):\n",
    "                for state in range(self.num_states):\n",
    "                    emission_aux[state][obs]+=prod_alpha_beta_normed[state][i]\n",
    "                    if i==0:\n",
    "                        continue\n",
    "                    else:\n",
    "                        for state2 in range(self.num_states):\n",
    "                            prev_step = alpha[state2][i-1]*tmat[state2][state]\n",
    "                            beta_now = beta[state][i]*emission[state][obs]\n",
    "                            #print(obs, state, state2,\n",
    "                            #      alpha[state][i-1], tmat[state][state2],\n",
    "                            #      beta[state][i],emission[state][obs])\n",
    "                            #print(obs, state, state2, prev_step*beta_now/(sum(prod_alpha_beta)[i]))\n",
    "                            transition_aux[state2][state] += prev_step * \\\n",
    "                                beta_now/(sum(prod_alpha_beta)[i])\n",
    "            new_tmat = np.zeros((self.num_states,self.num_states))\n",
    "            for si in range(self.num_states):\n",
    "                norm_factor = sum(prod_alpha_beta_normed[si])\n",
    "                for sj in range(self.num_states):\n",
    "                    new_tmat[sj][si] = transition_aux[si][sj]/norm_factor\n",
    "            print(transition_aux)\n",
    "            print(new_tmat)\n",
    "\n",
    "        return {\"a\": tmat, \"b\": emission}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ice cream debug\n",
    "tmat_weather = [[0.8, 0.2],\n",
    "[0.2,0.8]]\n",
    "emission = [[0.7,0.2,0.1],\n",
    "[0.1,0.2,0.7]]\n",
    "unsupervised = UnSupervised(tmat_weather,emission, [0.5,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function UnSupervised.baum_welch.<locals>.<lambda> at 0x7f7ed4c74c20>, {0: defaultdict(<class 'float'>, {0: 12.132497937565816, 1: 2.676301437433337}), 1: defaultdict(<class 'float'>, {0: 2.795184580166156, 1: 14.396016044834688})})\n",
      "[[0.80061975 0.15662704]\n",
      " [0.1766083  0.80667497]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'a': [[0.8, 0.2], [0.2, 0.8]], 'b': [[0.7, 0.2, 0.1], [0.1, 0.2, 0.7]]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = [1,2,2,1,2,1,2,1,1,2,0,2,2,0,0,0,1,0,0,0,2,0,1,0,0,0,1,2,2,1,2,1,1]\n",
    "unsupervised.calculate_alpha_forward(seq, tmat_weather, emission)\n",
    "unsupervised.calculate_beta_backward(seq, tmat_weather, emission)\n",
    "unsupervised.baum_welch(seq,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38d37c7b51a76fad05d5106cda319bdfc676f147592bff32468239985737bad5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
